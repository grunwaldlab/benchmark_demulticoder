---
title: "temp"
output: html_document
date: "2024-12-27"
---

---
title: "Pooled amplicon analysis-demulticoder"
output: html_document
date: "2024-05-21"
---

```{r setup}
library(phyloseq); packageVersion("phyloseq")
library(ggplot2); packageVersion("ggplot2")
library(readr); packageVersion("readr")
library(tidyr); packageVersion("tidyr")
library(purrr); packageVersion("purrr")
library(furrr); packageVersion("furrr")
library(dplyr); packageVersion("dplyr")
library(stringr); packageVersion("stringr")
library(forcats); packageVersion("forcats")
library(metacoder); packageVersion("metacoder")
library(data.table); packageVersion("data.table")
library(decontam); packageVersion("decontam")
library(Biostrings); packageVersion("Biostrings")
library(magick); packageVersion("magick")
library(vegan); packageVersion("vegan")
library(pdftools);packageVersion("pdftools")
library(vegan); packageVersion("vegan")
library(grid)
library(gridExtra)
knitr::opts_knit$set(root.dir = "~/benchmark_demulticoder")
```

```{r load reads}
seed <- 1
set.seed(seed)

asv_matrix_rps10<-read.csv("demulticoder/data/final_asv_abundance_matrix_rps10.csv")
asv_matrix_rps10$dada2_tax <- asv_matrix_rps10$dada2_tax <- gsub("Stramenopila", "Eukaryota--100--Domain;Stramenopila", asv_matrix_rps10$dada2_tax)
asv_matrix_rps10 <- asv_matrix_rps10[, -1]
colnames(asv_matrix_rps10)[3:ncol(asv_matrix_rps10)] <- gsub("_rps10$", "", colnames(asv_matrix_rps10)[3:ncol(asv_matrix_rps10)])

asv_matrix_rps10_oldb<-read.csv("demulticoder/data_olddb//final_asv_abundance_matrix_rps10.csv")
asv_matrix_rps10_oldb$dada2_tax <- asv_matrix_rps10_oldb$dada2_tax <- gsub("Stramenopila", "Eukaryota--100--Domain;Stramenopila", asv_matrix_rps10_oldb$dada2_tax)
asv_matrix_rps10_oldb <- asv_matrix_rps10_oldb[, -1]
colnames(asv_matrix_rps10_oldb)[3:ncol(asv_matrix_rps10_oldb)] <- gsub("_rps10$", "", colnames(asv_matrix_rps10_oldb)[3:ncol(asv_matrix_rps10_oldb)])

metadata_path <- file.path("demulticoder/data/metadata.csv")
metadata <- read_csv(metadata_path)
print(metadata)
```

### Convert ASV matrices to taxmap objects-updated db
```{r convert to taxmap obj}
obj_newdb <- parse_tax_data(asv_matrix_rps10, class_cols = 'dada2_tax', class_sep = ';',
                      class_regex = '^(.+)--(.+)--(.+)$',
                      class_key = c(taxon = 'taxon_name', boot = 'info', rank = 'taxon_rank'))
names(obj_newdb$data) <- c('abund', 'score')
obj_newdb <- transmute_obs(obj_newdb, 'score', sequence = sequence[input_index], boot = boot, rank = rank)


# For diversity calculations, we'll use proportions of read depth
# We'll set any proportion to 0 that is less than the inverse of the read count of the non-control sample with the fewest reads.
# This should account for unequal sample read depth without the randomness of rarefaction.

metadata$raw_count <- colSums(obj_newdb$data$abund[, metadata$sample_name])
lowest_count <- min(metadata$raw_count[! is.na(metadata$organism)])
lowest_count
obj_newdb$data$prop <- calc_obs_props(obj_newdb, data = 'abund', cols = metadata$sample_name)
obj_newdb$data$prop <- zero_low_counts(obj_newdb, data = 'prop', min_count = 1 / lowest_count, cols = metadata$sample_name)
obj_newdb$data$prop

obj_newdb$data$prop[metadata$sample_name] <- map(metadata$sample_name, function(id) {
  out <- obj_newdb$data$prop[[id]]
  out[is.na(out) | is.nan(out)] <- 0
  out
})

obj_newdb$data$prop
```

### Convert ASV matrices to taxmap objects-old db
```{r convert to taxmap obj}
obj_olddb <- parse_tax_data(asv_matrix_rps10_oldb, class_cols = 'dada2_tax', class_sep = ';',
                      class_regex = '^(.+)--(.+)--(.+)$',
                      class_key = c(taxon = 'taxon_name', boot = 'info', rank = 'taxon_rank'))
names(obj_olddb$data) <- c('abund', 'score')
obj_olddb <- transmute_obs(obj_olddb, 'score', sequence = sequence[input_index], boot = boot, rank = rank)


# For diversity calculations, we'll use proportions of read depth
# We'll set any proportion to 0 that is less than the inverse of the read count of the non-control sample with the fewest reads.
# This should account for unequal sample read depth without the randomness of rarefaction.

metadata$raw_count <- colSums(obj_olddb$data$abund[, metadata$sample_name])
lowest_count <- min(metadata$raw_count[! is.na(metadata$organism)])
lowest_count
obj_olddb$data$prop <- calc_obs_props(obj_olddb, data = 'abund', cols = metadata$sample_name)
obj_olddb$data$prop <- zero_low_counts(obj_olddb, data = 'prop', min_count = 1 / lowest_count, cols = metadata$sample_name)
obj_olddb$data$prop

obj_olddb$data$prop[metadata$sample_name] <- map(metadata$sample_name, function(id) {
  out <- obj_olddb$data$prop[[id]]
  out[is.na(out) | is.nan(out)] <- 0
  out
})

obj_olddb$data$prop
```

### Community composition plot-new db-showcase differences in bootstrap support values
```{r, overall community plot new db}
min_bootstrap <- 0
obj_newdb$data$score$boot <- as.numeric(obj_newdb$data$score$boot)
max_boot <- obj_newdb$data$score %>%
  group_by(taxon_id) %>%
  summarise(max = max(boot))
max_boot <- setNames(max_boot$max, max_boot$taxon_id)
obj_newdb <- filter_taxa(obj_newdb, max_boot[taxon_ids] >= min_bootstrap | taxon_ranks %in% c("ASV", "Reference"), reassign_obs = c(abund = TRUE, score = FALSE))

obj_newdb$data$asv_prop <- calc_obs_props(obj_newdb, 'abund', cols = metadata$sample_name)
obj_newdb$data$tax_abund <- calc_taxon_abund(obj_newdb, 'abund', cols = metadata$sample_name)
obj_newdb$data$tax_prop <- calc_taxon_abund(obj_newdb, 'asv_prop', cols = metadata$sample_name)
obj_newdb$data$tax_data <- calc_n_samples(obj_newdb, 'tax_prop', cols = metadata$sample_name[metadata$sample_type == 'Sample'])
obj_newdb$data$tax_data$mean_prop <- rowMeans(obj_newdb$data$tax_prop[, metadata$sample_name])

obj_newdb %>%
  filter_taxa(taxon_ranks == "Species", supertaxa = TRUE, reassign_obs = c(tax_abund = FALSE)) 

# Calculate the relative standard deviation for each taxon as a measure of how consistently it was found.
rsd <- function(x, na.rm = FALSE) {sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)}
obj_newdb$data$tax_data$rel_stand_dev <- map_dbl(1:nrow(obj_newdb$data$tax_abund), function(i) {
  rsd(unlist(obj_newdb$data$tax_abund[i, metadata$sample_name]), na.rm = TRUE)
})

max_boot <- obj_newdb$data$score %>%
  group_by(taxon_id) %>%
  summarise(max = max(boot))

# Map the maximum bootstrap support to taxon IDs
max_boot <- setNames(max_boot$max, max_boot$taxon_id)

# Add maximum bootstrap support to tax_data
obj_newdb$data$tax_data$max_boot <- max_boot[match(obj_newdb$data$tax_data$taxon_id, names(max_boot))]


set.seed(1)

obj_newdb %>%
  filter_taxa(! is_stem) %>%
  filter_taxa(n_samples >= 10, supertaxa = TRUE, reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "_sp$"), reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "incertae_sedis", ignore.case = TRUE), reassign_obs = FALSE) %>%
  remove_redundant_names() %>%
  heat_tree(node_size = mean_prop,
            edge_size = n_samples,
            node_color = ifelse(is.na(max_boot), 0, max_boot),
            node_color_range = c("#D2042D","#fc8d62","#a6d854","#66c2a5","#8da0cb","gray"),
            node_label = taxon_names,
            node_size_range = c(0.008, 0.025),
            node_label_size_range = c(0.012, 0.018),
            edge_label_size_range = c(0.010, 0.013),
            node_size_interval = c(0, 1),
            edge_size_range = c(0.001, 0.008),
            layout = "da", initial_layout = "re",
            node_color_axis_label = "Bootstrap support",
            node_size_axis_label = "Mean proportion of reads",
            edge_size_axis_label = "Number of samples",
            node_color_digits = 2,
            node_size_digits = 2,
            edge_color_digits = 2,
            edge_size_digits = 2,
            aspect_ratio = 1.618,
            output_file = file.path('demulticoder/figures', '/heattree_mostabund_taxa_rps10_newdb.pdf'))
```

### Community composition plot-old db-showcase differences in bootstrap support values
```{r, overall community plot}
### Community composition plot-new db-showcase differences in bootstrap support values
min_bootstrap <- 0
obj_olddb$data$score$boot <- as.numeric(obj_olddb$data$score$boot)
max_boot <- obj_olddb$data$score %>%
  group_by(taxon_id) %>%
  summarise(max = max(boot))
max_boot <- setNames(max_boot$max, max_boot$taxon_id)
obj_olddb <- filter_taxa(obj_olddb, max_boot[taxon_ids] >= min_bootstrap | taxon_ranks %in% c("ASV", "Reference"), reassign_obs = c(abund = TRUE, score = FALSE))

obj_olddb$data$asv_prop <- calc_obs_props(obj_olddb, 'abund', cols = metadata$sample_name)
obj_olddb$data$tax_abund <- calc_taxon_abund(obj_olddb, 'abund', cols = metadata$sample_name)
obj_olddb$data$tax_prop <- calc_taxon_abund(obj_olddb, 'asv_prop', cols = metadata$sample_name)
obj_olddb$data$tax_data <- calc_n_samples(obj_olddb, 'tax_prop', cols = metadata$sample_name[metadata$sample_type == 'Sample'])
obj_olddb$data$tax_data$mean_prop <- rowMeans(obj_olddb$data$tax_prop[, metadata$sample_name])

obj_olddb %>%
  filter_taxa(taxon_ranks == "Species", supertaxa = TRUE, reassign_obs = c(tax_abund = FALSE)) 

# Calculate the relative standard deviation for each taxon as a measure of how consistently it was found.
rsd <- function(x, na.rm = FALSE) {sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)}
obj_olddb$data$tax_data$rel_stand_dev <- map_dbl(1:nrow(obj_olddb$data$tax_abund), function(i) {
  rsd(unlist(obj_olddb$data$tax_abund[i, metadata$sample_name]), na.rm = TRUE)
})

max_boot <- obj_olddb$data$score %>%
  group_by(taxon_id) %>%
  summarise(max = max(boot))

# Map the maximum bootstrap support to taxon IDs
max_boot <- setNames(max_boot$max, max_boot$taxon_id)

# Add maximum bootstrap support to tax_data
obj_olddb$data$tax_data$max_boot <- max_boot[match(obj_olddb$data$tax_data$taxon_id, names(max_boot))]


set.seed(1)

obj_olddb %>%
  filter_taxa(! is_stem) %>%
  filter_taxa(n_samples >= 10, supertaxa = TRUE, reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "_sp$"), reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "incertae_sedis", ignore.case = TRUE), reassign_obs = FALSE) %>%
  remove_redundant_names() %>%
  heat_tree(node_size = mean_prop,
            edge_size = n_samples,
            node_color = ifelse(is.na(max_boot), 0, max_boot),
            node_color_range = c("#D2042D","#fc8d62","#a6d854","#66c2a5","#8da0cb","gray"),
            node_label = taxon_names,
            node_size_range = c(0.008, 0.025),
            node_label_size_range = c(0.012, 0.018),
            edge_label_size_range = c(0.010, 0.013),
            node_size_interval = c(0, 1),
            edge_size_range = c(0.001, 0.008),
            layout = "da", initial_layout = "re",
            node_color_axis_label = "Bootstrap support",
            node_size_axis_label = "Mean proportion of reads",
            edge_size_axis_label = "Number of samples",
            node_color_digits = 2,
            node_size_digits = 2,
            edge_color_digits = 2,
            edge_size_digits = 2,
            aspect_ratio = 1.618,
            output_file = file.path('demulticoder/figures', '/heattree_mostabund_taxa_rps10_olddb.pdf'))
```

Let's facet the two plots so we have a side-by-side comparison of the two databases. 
```{r, facet community plot,fig.height=30, fig.width=30, message=FALSE, echo=FALSE}
# Read the images
old_db <- magick::image_read_pdf("demulticoder/figures/heattree_mostabund_taxa_rps10_olddb.pdf")
new_db <- magick::image_read_pdf("demulticoder/figures/heattree_mostabund_taxa_rps10_newdb.pdf")

# Convert to grobs
old_grob <- grid::rasterGrob(as.raster(old_db))
new_grob <- grid::rasterGrob(as.raster(new_db))

# Create a layout with larger bottom plots
pdf("demulticoder/figures/combined_heat_trees_db_compare.pdf", width=10, height=12)
grid.newpage()
pushViewport(viewport(layout = grid.layout(3, 2, 
                                           heights = unit(c(0.1, 1, 1.5), "null"),
                                           widths = unit(c(1, 1), "null"))))

# Function to place grobs with labels
place_grob <- function(grob, row, col, label) {
  pushViewport(viewport(layout.pos.row = row, layout.pos.col = col))
  grid.text(label, y = unit(1, "npc") + unit(0.5, "lines"), 
            gp = gpar(fontsize = 12, fontface = "bold"))
  pushViewport(viewport(height = unit(0.9, "npc")))
  grid.draw(grob)
  upViewport(2)
}

# Place grobs with labels
place_grob(old_grob, 2, 1, "A. Old database")
place_grob(new_grob, 2, 2, "B. New database")

dev.off()
```

### Summary stats comparing db
```{r, summary stats, message=FALSE, echo=FALSE}
# Load necessary libraries
library(dplyr)

# Load your old and new database matrices
old_db <- read.csv("path_to_old_db.csv", sep = "\t")
new_db <- read.csv("path_to_new_db.csv", sep = "\t")

# Extract the taxonomic assignments and bootstrap support values
old_taxa <- old_db %>% select(asv_id, dada2_tax)
new_taxa <- new_db %>% select(asv_id, dada2_tax)

# Merge the old and new taxonomic assignments on asv_id
merged_taxa <- merge(old_taxa, new_taxa, by = "asv_id", suffixes = c("_old", "_new"))

# Calculate the number of taxa with high bootstrap support in the old and new databases
high_support_old <- sum(old_db[, 4:ncol(old_db)] >= 80, na.rm = TRUE)
high_support_new <- sum(new_db[, 4:ncol(new_db)] >= 80, na.rm = TRUE)

# Calculate the number of newly assigned taxa in the new database
newly_assigned_taxa <- nrow(merged_taxa %>% filter(dada2_tax_old != dada2_tax_new))

# Calculate the number of taxa present in both databases but with different bootstrap support values
changed_support_taxa <- nrow(merged_taxa %>% filter(dada2_tax_old == dada2_tax_new & 
                                                    rowSums(old_db[, 4:ncol(old_db)], na.rm = TRUE) != 
                                                    rowSums(new_db[, 4:ncol(new_db)], na.rm = TRUE)))

# Print summary statistics
cat("Number of taxa with high bootstrap support in the old database:", high_support_old, "\n")
cat("Number of taxa with high bootstrap support in the new database:", high_support_new, "\n")
cat("Number of newly assigned taxa in the new database:", newly_assigned_taxa, "\n")
cat("Number of taxa present in both databases but with different bootstrap support values:", changed_support_taxa, "\n")
```